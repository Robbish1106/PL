# -*- coding: utf-8 -*-
"""HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16LuysnBfqWqb33X_QnuQOwrQlXeGGRUZ
"""

import urllib.request as req
import json
import pandas as pd
import numpy

#輸入要爬的網頁網址 (這邊的程式碼只適用PTT喔，最好是有標題的那種)
url= "https://www.ptt.cc/bbs/C_Chat/index.html"

#建立一個Request物件，附加Request Headers的資訊 (讓被使用的網頁知道你的作業系統等使用者資訊)
request=req.Request(url, headers={
    "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36"
})

#將網頁原始碼讀出
with req.urlopen(request) as response:
    data=response.read().decode("utf-8")

#將帶有標題的資料篩出，其他去掉
import bs4
root=bs4.BeautifulSoup(data, "html.parser")
titles=root.find_all("div", class_="title")
for title in titles:
    if title.a !=None:
        print(title.a.string)

#將有效資料放入列表
temp = []
for title in titles:
    if title.a !=None:
        temp.append(title.a.string)

temp

#把列表轉成dataframe
df = pd.DataFrame(temp)
print(df)

#把dataframe轉成csv
df.to_csv('CHAT.csv')

#把dataframe轉成json (有亂碼)
df.to_json('CHAT.json')

#把dataframe轉成dict
temp1 = df.to_dict()
temp1

#把dict轉成json (沒有亂碼)
with open('CHAT.json','w',encoding='utf-8') as file:
    json.dump(temp1,file,ensure_ascii=False)